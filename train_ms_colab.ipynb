{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E72yExwqd54K","executionInfo":{"status":"ok","timestamp":1664897990233,"user_tz":-480,"elapsed":6503,"user":{"displayName":"xin ma","userId":"15070962203055710637"}},"outputId":"332c79af-0e94-4284-c622-657e0804e790"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys\n","import os\n","sys.path.append('/content/drive/My Drive/VITS/')\n","#改变当前工作目录到谷歌云盘的路径\n","path=\"/content/drive/My Drive/VITS/\"\n","os.chdir(path)"],"metadata":{"id":"GdGmf8_4e5FH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install -r requirements.txt"],"metadata":{"id":"IERml-OHj1_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train_ms.py -c configs/genshin_base_ms.json -m genshin_base"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lp78hezKfxhw","executionInfo":{"status":"ok","timestamp":1664898535913,"user_tz":-480,"elapsed":477733,"user":{"displayName":"xin ma","userId":"15070962203055710637"}},"outputId":"0147c392-48c3-47bf-b92e-b3f6da9dd60a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] {'train': {'log_interval': 200, 'eval_interval': 1000, 'seed': 1234, 'epochs': 4000, 'learning_rate': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 16, 'fp16_run': True, 'lr_decay': 0.999875, 'segment_size': 8192, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'training_files': 'filelists/train_filelist.txt.cleaned', 'validation_files': 'filelists/val_filelist.txt.cleaned', 'text_cleaners': ['chinese_cleaners1'], 'max_wav_value': 32768.0, 'sampling_rate': 48000, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': None, 'add_blank': True, 'n_speakers': 50, 'cleaned_text': True}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'n_layers_q': 3, 'use_spectral_norm': False, 'gin_channels': 256}, 'model_dir': './logs/genshin_base'}\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:607: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:800.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:607: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at  ../aten/src/ATen/EmptyTensor.cpp:31.)\n","  normalized, onesided, return_complex)\n","/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py:175: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n","grad.sizes() = [1, 9, 96], strides() = [12000, 96, 1]\n","bucket_view.sizes() = [1, 9, 96], strides() = [864, 96, 1] (Triggered internally at  ../torch/csrc/distributed/c10d/reducer.cpp:312.)\n","  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","[INFO] Train Epoch: 1 [0%]\n","[INFO] [5.96839714050293, 5.96811580657959, 0.3754759728908539, 104.85639190673828, 2.343719244003296, 223.0587615966797, 0, 0.0002]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[INFO] Saving model and optimizer state at iteration 1 to checkpoints/G_ms.pth\n","[INFO] Saving model and optimizer state at iteration 1 to checkpoints/D_ms.pth\n","[INFO] ====> Epoch: 1\n","[INFO] ====> Epoch: 2\n","[INFO] ====> Epoch: 3\n","[INFO] ====> Epoch: 4\n","[INFO] ====> Epoch: 5\n","[INFO] ====> Epoch: 6\n","[INFO] ====> Epoch: 7\n","[INFO] ====> Epoch: 8\n","[INFO] ====> Epoch: 9\n","[INFO] ====> Epoch: 10\n","[INFO] ====> Epoch: 11\n","[INFO] ====> Epoch: 12\n","[INFO] ====> Epoch: 13\n","[INFO] ====> Epoch: 14\n","[INFO] ====> Epoch: 15\n","[INFO] ====> Epoch: 16\n","[INFO] ====> Epoch: 17\n","Traceback (most recent call last):\n","  File \"train_ms.py\", line 301, in <module>\n","  File \"train_ms.py\", line 55, in main\n","    mp.spawn(run, nprocs=n_gpus, args=(n_gpus, hps,))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 240, in spawn\n","    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 198, in start_processes\n","    while not context.join():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 111, in join\n","    timeout=timeout,\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lPVVgsdnd54N","executionInfo":{"status":"ok","timestamp":1664898535914,"user_tz":-480,"elapsed":11,"user":{"displayName":"xin ma","userId":"15070962203055710637"}},"outputId":"bdb622e0-a9d3-4acb-f945-5d7534b55c24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Oct  4 15:48:55 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   66C    P0    40W /  70W |      3MiB / 15109MiB |     19%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"}},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}